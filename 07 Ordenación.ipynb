{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Ordenación\n",
    "\n",
    "El problema de ordenar un conjunto de datos (por ejemplo, en orden ascendente) tiene gran importancia tanto teórica como práctica. En esta sección veremos principalmente algoritmos que ordenan mediante comparaciones entre llaves, para los cuales se puede demostrar una cota inferior que coincide con la cota superior provista por varios algoritmos. También veremos un algoritmo de otro tipo, que al no hacer comparaciones, no está sujeto a esa cota inferior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cota inferior\n",
    "\n",
    "Supongamos que deseamos ordenar tres datos $A$, $B$ y $C$. La siguiente figura muestra un árbol de decisión posible para resolver este problema. Los nodos internos del árbol representan comparaciones y los nodos externos representan salidas emitidas por el programa.\n",
    "\n",
    "![arbol-decision-ordenacion](arbol-decision-ordenacion.gif)\n",
    "\n",
    "Como se vio en el capítulo de búsqueda, todo árbol de decisión con $H$ hojas tiene al menos altura $\\log_2{H}$, y la altura del árbol de decisión es igual al número de comparaciones que se efectúan en el peor caso.\n",
    "\n",
    "En un árbol de decisión para ordenar $n$ datos se tiene que $H=n!$, y por lo tanto se tiene que todo algoritmo que ordene $n$ datos mediante comparaciones entre llaves debe hacer al menos $\\log_2{n!}$ comparaciones en el peor caso.\n",
    "\n",
    "Usando la aproximación de Stirling, se puede demostrar que $\\log_2{n!} = n \\log_2{n} + \\Theta(n)$, por lo cual la cota inferior es de $\\Theta(n\\log{n})$.\n",
    "\n",
    "Si suponemos que todas las posibles permutaciones resultantes son equiprobables, es posible demostrar también que el número promedio de comparaciones que cualquier algoritmo debe hacer es también de $\\Theta(n\\log{n})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quicksort\n",
    "\n",
    "Este método fue inventado por C.A.R. Hoare a comienzos de los '60s, y sigue siendo el método más eficiente para uso general.\n",
    "\n",
    "Quicksort es un ejemplo clásico de la aplicación del principio de *dividir para reinar*. Su estructura es la siguiente:\n",
    "\n",
    "* Primero se elige un elemento al azar, que se denomina el pivote.\n",
    "\n",
    "* El arreglo a ordenar se reordena dejando a la izquierda a los elementos menores que el pivote, el pivote al medio, y a la derecha los elementos mayores que el pivote:\n",
    "\n",
    "![particion](particion.gif)\n",
    "\n",
    "* Luego cada sub-arreglo se ordena recursivamente.\n",
    "\n",
    "La recursividad termina, en principio, cuando se llega a sub-arreglos de tamaño cero o uno, los cuales trivialmente ya están ordenados. En la práctica veremos que es preferible detener la recursividad antes de eso, para no desperdiciar tiempo ordenando recursivamente arreglos pequeños, los cuales pueden ordenarse más eficientemente usando Ordenación por Inserción, por ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quicksort(a):\n",
    "    qs(a,0,len(a)-1)\n",
    "\n",
    "def qs(a,i,j): # ordena a[i],...,a[j]\n",
    "    if i<j: # quedan 2 o más elementos por ordenar\n",
    "        k=particion(a,i,j)\n",
    "        qs(a,i,k-1)\n",
    "        qs(a,k+1,j)\n",
    "\n",
    "def particion(a,i,j): # particiona a[i],...,a[j], retorna en k posición del pivote\n",
    "    k=np.random.randint(i,j) # genera un número al azar k en i..j\n",
    "    (a[i],a[k])=(a[k],a[i]) # mueve a[k] al extremo izquierdo\n",
    "    # a[i] es el pivote\n",
    "    s=i # invariante: a[i+1..s]<=p, a[s+1..t]>p\n",
    "    for t in range(s,j):\n",
    "        if a[t+1]<=a[i]:\n",
    "            (a[s+1],a[t+1])=(a[t+1],a[s+1])\n",
    "            s=s+1\n",
    "    # mover pivote al centro\n",
    "    (a[i],a[s])=(a[s],a[i])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20423073 0.20768937 0.81650528 0.1804613  0.71118114 0.54139117]\n",
      "[0.1804613  0.20423073 0.20768937 0.54139117 0.71118114 0.81650528]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.random(6)\n",
    "print(a)\n",
    "quicksort(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costo promedio de Quicksort\n",
    "\n",
    "Si suponemos, como una primera aproximación, que el pivote siempre resulta ser la mediana del conjunto, entonces el costo de ordenar está dado (aproximadamente) por la ecuación de recurrencia\n",
    "\n",
    "$$\n",
    "T(n)=n+2T\\left( \\frac{n}{2} \\right)\n",
    "$$\n",
    "\n",
    "Esto tiene solución $T(n) = n \\log_2{n}$ y es, en realidad, el *mejor* caso de Quicksort.\n",
    "\n",
    "Para analizar el tiempo promedio que demora la ordenación mediante Quicksort, observemos que el funcionamiento de Quicksort puede graficarse mediante un *árbol de partición*:\n",
    "\n",
    "![arbol-particion](arbol-particion.gif)\n",
    "\n",
    "Por la forma en que se construye, es fácil ver que el árbol de partición es un *árbol de búsqueda binaria*, y como el pivote es escogido al azar, entonces la raíz de cada subárbol puede ser cualquiera de los elementos del conjunto en forma equiprobable. En consecuencia, los árboles de partición y los árboles de búsqueda binaria tienen exactamente la misma distribución.\n",
    "\n",
    "En el proceso de partición, cada elemento de los subárboles ha sido comparado contra la raíz (el pivote). Al terminar el proceso, cada elemento ha sido comparado contra todos sus ancestros. Si sumamos todas estas comparaciones, el resultado total es igual al *largo de caminos internos*.\n",
    "\n",
    "Usando todas estas correspondencias, tenemos que, usando los resultados ya conocidos para árboles, el número promedio de comparaciones que realiza Quicksort es de:\n",
    "\n",
    "$$\n",
    "T(n)=1.38 n\\log_2{n}+\\Theta(n)\n",
    "$$\n",
    "\n",
    "Por lo tanto, Quicksort, en el caso esperado, corre en un tiempo proporcional a la cota inferior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peor caso de Quicksort\n",
    "\n",
    "El peor caso de Quicksort se produce cuando el pivote resulta ser siempre el mínimo o el máximo del conjunto. En este caso la ecuación de recurrencia es\n",
    "\n",
    "$$\n",
    "T(n) = n - 1 + T(n-1)\n",
    "$$\n",
    "            \n",
    "lo que tiene solución $T(n) = \\Theta(n^2)$. Desde el punto de vista del árbol de partición, esto corresponde a un árbol en \"zig-zag\".\n",
    "\n",
    "Si bien este peor caso es extremadamente improbable si el pivote se escoge al azar, algunas implementaciones de Quicksort toman como pivote al primer elemento del arreglo (suponiendo que, al venir el arreglo al azar, entonces el primer elemento es tan aleatorio como cualquier otro). El problema es que si el conjunto viene en realidad ordenado, entonces caemos justo en el peor caso cuadrático.\n",
    "\n",
    "Lo anterior refuerza la importancia de que el pivote se escoja al azar. Esto no aumenta significativamente el costo total, porque el número total de elecciones de pivote es $\\Theta(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejoras a Quicksort\n",
    "\n",
    "Quicksort puede ser optimizado de varias maneras, pero hay que ser muy cuidadoso con estas mejoras, porque es fácil que terminen empeorando el desempeño del algoritmo.\n",
    "\n",
    "En primer lugar, es desaconsejable hacer cosas que aumenten la cantidad de trabajo que se hace dentro del \"loop\" de partición, porque este es el lugar en donde se concentra el costo $\\Theta(n \\log{n})$.\n",
    "\n",
    "Algunas de las mejoras que han dado buen resultado son las siguientes:\n",
    "\n",
    "#### Quicksort con \"mediana de 3\"\n",
    "\n",
    "En esta variante, el pivote no se escoge como un elemento tomado al azar, sino que primero se extrae una muestra de 3 elementos, y entre ellos se escoge a la mediana de esa muestra como pivote.\n",
    "\n",
    "Si la muestra se escoge tomando al primer elemento del arreglo, al del medio y al último, entonces lo que era el peor caso (arreglo ordenado) se transforma de inmediato en mejor caso.\n",
    "\n",
    "De todas formas, es aconsejable que la muestra se escoja al azar, y en ese caso el análisis muestra que el costo esperado para ordenar n elementos es\n",
    "\n",
    "$$\n",
    "\\frac{12}{7} n \\ln{n}  \\approx  1.19 n \\log_2{n}\n",
    "$$\n",
    "\n",
    "Esta reducción en el costo se debe a que el pivote es ahora una mejor aproximación a la mediana. De hecho, si en lugar de escoger una muestra de tamaño 3, lo hiciéramos con tamaños como 7, 9, etc., se lograría una reducción aún mayor, acercándonos cada vez más al óptimo, pero con rendimientos rápidamente decrecientes.\n",
    "\n",
    "#### Uso de Ordenación por Inserción para ordenar sub-arreglos pequeños\n",
    "\n",
    "Tal como se dijo antes, no es eficiente ordenar recursivamente sub-arreglos demasiado pequeños.\n",
    "\n",
    "En lugar de esto, se puede establecer un tamaño mínimo $M$, de modo que los sub-arreglos de tamaño menor que esto se ordenan por inserción en lugar de por Quicksort.\n",
    "\n",
    "Claramente debe haber un valor óptimo para $M$, porque si creciera indefinidamente se llegaría a un algoritmo cuadrático. Esto se puede analizar, y el óptimo es cercano a 10.\n",
    "\n",
    "Como método de implementación, al detectarse un sub-arreglo de tamaño menor que $M$, se lo puede dejar simplemente sin ordenar, retornando de inmediato de la recursividad. Al final del proceso, se tiene un arreglo cuyos pivotes están en orden creciente, y encierran entre ellos a bloques de elementos desordenados, pero que ya están en el grupo correcto. Para completar la ordenación, entonces, basta con hacer una sola gran pasada de Ordenación por Inserción, la cual ahora no tiene costo $\\Theta(n^2)$, sino $\\Theta(nM)$, porque ningún elemento está a distancia mayor que $M$ de su ubicación definitiva.\n",
    "\n",
    "#### Ordenar recursivamente sólo el sub-arreglo más pequeño\n",
    "\n",
    "Un problema potencial con Quicksort es la profundidad que puede llegar a tener la recursividad. En el peor caso, ésta puede llegar a ser $\\Theta(n)$.\n",
    "\n",
    "Para evitar esto, se puede usar recursividad solo para la \"mitad\" más pequeña, y ordenar la otra \"mitad\" de manera iterativa. Con este enfoque, cada llamada recursiva se aplica a un sub-arreglo cuyo tamaño es a lo más la mitad del tamaño del arreglo a ordenar, de modo que si llamamos $S(n)$ a la profundidad de recursión, tenemos que\n",
    "\n",
    "$$\n",
    "S(n) \\le 1 + S\\left(\\frac{n}{2}\\right)\n",
    "$$\n",
    "\n",
    "lo cual tiene solución $\\log_2{n}$, de modo que la profundidad de la recursión nunca es más que logarítmica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qs(a,i,j): # ordena a[i],...,a[j]\n",
    "    while i<j: # quedan 2 o más elementos por ordenar\n",
    "        k=particion(a,i,j)\n",
    "        if k-i<=j-k: #mitad izquierda es más pequeña\n",
    "            qs(a,i,k-1)\n",
    "            i=k+1\n",
    "        else:\n",
    "            qs(a,k+1,j)\n",
    "            j=k-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56382863 0.00164504 0.70130608 0.15055317 0.97007422 0.93080778]\n",
      "[0.00164504 0.15055317 0.56382863 0.70130608 0.93080778 0.97007422]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.random(6)\n",
    "print(a)\n",
    "quicksort(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
